Dat$logitpsi <- with(Dat, beta0 + b0 + beta3*Trt*Yr)
Dat$psi <- 1/(1+exp(-Dat$logitpsi))
Dat2 <- data.frame(Yr = rep(Dat$Yr, each=S),
Stand = rep(Dat$Stand, each=S),
Trt = rep(Dat$Trt, each=S),
StandYr = rep(Dat$StandYr, each=S),
psi = rep(Dat$psi, each=S))
occ <- rbinom(nrow(Dat2), 1, Dat2$psi)
detection <- cbind(rbinom(nrow(Dat2), 1, det*occ),
rbinom(nrow(Dat2), 1, det*occ),
rbinom(nrow(Dat2), 1, det*occ))
zst <- apply(detection, 1, max)
test.data <- list(y=detection, R=R, N=R*2, n=R*S*2, Trt=Dat$Trt, Yr=Dat$Yr, TrtYr= Dat$Trt * Dat$Yr,
StandID=Dat$Stand, StandYr = Dat2$StandYr)
list(test.data=test.data, zst=zst, Z=occ, psi=Dat2$psi)
}
fit1 <- function(dat, params, model, n.chains, n.thin, n.iter, n.burnin){
inits <- function(){list(Z=dat$zst)}
out <- jags(data=dat$test.data, inits=inits, parameters.to.save=params, model.file=model,
n.chains=n.chains, n.thin=n.thin, n.iter=n.iter, n.burnin=n.burnin)
out
}
runSim <- function(sets, nsim, params, model, n.chains, n.thin, n.iter, n.burnin, dfile){
nsets <- nrow(sets)
for(i in 1:nsets){
R <- sets$R[i]
S <- sets$S[i]
posttrt <- sets$posttrt[i]
det <- sets$det[i]
for(j in 1:nsim){
dat.ij <- genData1(R=R, S=S, posttrt=posttrt, det=det)
fm.ij <- fit1(dat.ij, params=params, model=model, n.chains=n.chains, n.thin=n.thin, n.iter=n.iter, n.burnin=n.burnin)
fname <- paste("Nstand.", R, "_Nsub.", S, "_Posttrt.", posttrt, "_det.", det, "_sim.", j, ".csv",sep="")
write.csv(fm.ij$BUGSoutput$summary, paste(dfile, fname, sep=""))
}
}
}
sets <- expand.grid(R=c(20, 30, 40, 50, 60), S=c(5, 7, 9), posttrt=c(0.1, 0.3), det=c(0.15, 0.30, 0.50))
params <- c("aInt.mean", "bTrt", "bYr", "bTrtYr", "gInt")
nsim=500
system.time(temp <- runSim(sets=sets, nsim=nsim, params=params, model=model.h, n.chains=3, n.thin=10, n.iter=10000, n.burnin=5000, dfile="C:/"))
dfile
View(sets)
sets <- expand.grid(R=c(20, 30, 40, 50, 60), S=c(5, 7, 9), posttrt=c(0.1, 0.3), det=c(0.15, 0.30, 0.50))
params <- c("aInt.mean", "bTrt", "bYr", "bTrtYr", "gInt")
nsim=500
system.time(temp <- runSim(sets=sets, nsim=nsim, params=params, model=model.h, n.chains=3, n.thin=10, n.iter=10000, n.burnin=5000,
dfile="C:\Users\jasmi\OneDrive\Documents\Academic\OSU\Git\oss-occu\2015\output"))
sets <- expand.grid(R=c(20, 30, 40, 50, 60), S=c(5, 7, 9), posttrt=c(0.1, 0.3), det=c(0.15, 0.30, 0.50))
params <- c("aInt.mean", "bTrt", "bYr", "bTrtYr", "gInt")
nsim=500
system.time(temp <- runSim(sets=sets, nsim=nsim, params=params, model=model.h, n.chains=3, n.thin=10, n.iter=10000, n.burnin=5000,
dfile="C:/Users/jasmi/OneDrive/Documents/Academic/OSU/Git/oss-occu/2015/output"))
sets <- expand.grid(R=c(20, 30, 40, 50, 60), S=c(5), posttrt=c(0.1, 0.3), det=c(0.15, 0.30, 0.50))
params <- c("aInt.mean", "bTrt", "bYr", "bTrtYr", "gInt")
nsim=1
system.time(temp <- runSim(sets=sets, nsim=nsim, params=params, model=model.h, n.chains=3, n.thin=10, n.iter=10000, n.burnin=5000,
dfile="C:/Users/jasmi/OneDrive/Documents/Academic/OSU/Git/oss-occu/2015/output"))
sets <- expand.grid(R=c(20), S=c(5), posttrt=c(0.1, 0.3), det=c(0.15, 0.30, 0.50))
params <- c("aInt.mean", "bTrt", "bYr", "bTrtYr", "gInt")
nsim=2
system.time(temp <- runSim(sets=sets, nsim=nsim, params=params, model=model.h, n.chains=3, n.thin=10, n.iter=10000, n.burnin=5000,
dfile="C:/Users/jasmi/OneDrive/Documents/Academic/OSU/Git/oss-occu/2015/output"))
osslist[["OWBLM1"]]
unlink("Academic/OSU/Git/multivariate-analysis/homework2_cache", recursive = TRUE)
install.packages("rmarkdown")
install.packages("rmarkdown")
statsals <- stat.desc(sals)
knitr::opts_chunk$set(echo = TRUE)
setwd("C:/Users/jasmi/OneDrive/Documents/Academic/OSU/Git/multivariate-analysis")
library(vegan)
library(pastecs)
library(corrplot)
library(ggplot2)
library(ggpubr)
data <- read.csv("habitat.occu.complete.csv",row.names=1)
source("biostats.R")
colnames(data)
drop <- c(2:5,7:9,11:13,22)
data_subset <- data[,-drop]
sals <- data_subset[,12:17]
env <- data_subset[,1:11]
head(sals)
head(env)
na_count <- colSums(is.na(data))
print(na_count)
spe_pres <- apply(sals > 0, 2, sum) #Number of occurrences
sort(spe_pres)
ac <- table(unlist(sals)) #Number of cases for each abundance class
sals_red <- drop.var(sals, min.po=5)
ac2 <- table(unlist(sals_red))
par(mfrow = c(1,2))
barplot(ac,
las = 1,
xlab = "Abundance class",
ylab = "Frequency",
col = gray(length(ac): 0/length(ac)),
ylim=c(0,5000)
)
barplot(ac2,
las = 1,
xlab = "Abundance class, reduced",
ylab = "Frequency",
col = gray(length(ac): 0/length(ac)),
ylim=c(0,1500)
)
sals <- sals_red
statsals <- stat.desc(sals)
View(statsals)
statsals$coef.var
env_cont <- env[,c("elev","temp","hum","soil_moist_avg","jul_date")]
env.log <- data.trans(env_cont, method="log", plot=F)
env.power <- data.trans(env_cont, method="power", exp=0.5, plot=F)
env.asin <- data.trans(env_cont, method="asin", plot=F)
env.scal <- decostand(env_cont, "max") #Standardization by max value of each column
env.relsp <- decostand(env_cont, "total", MARGIN=2) #Standardization by column totals
env.zscore <- decostand(env_cont, "standardize") #Z-scores the data in each column
env.rel <- decostand(env_cont, "total") #Standardization by max value of each site/row
env.norm <- decostand(env_cont, "normalize") #Give a length of 1 to each row vector (chord
#transformation), very useful for Euclidean distances (PCA, RDA) and can be used on
#log-transformed data
env.hel <- decostand(env_cont, "hellinger") #Square root of relative values per site, obtained
#by applying chord transformation to square root transformed data
env.chi <- decostand(env_cont, "chi.square") #Double standardization by columns and rows
env.wis <- wisconsin(env_cont) #Wisconsin standardization, values are ranged by column maxima
#and then by site totals
#Let's see what each of these transformations looks like for the "Max Depth (m)" variable:
par(mfrow = c(2,2))
boxplot(env_cont$elev,
env.power$elev,
env.log$elev,
las = 1,
main = "Simple Transformations",
names = c("raw data","sqrt","log"),
col = "#FF5050"
)
boxplot(env.scal$elev,
env.relsp$elev,
env.zscore$elev,
las = 1,
main = "Standardizations by Variable",
names = c("max","total","Z-score"),
col = "#9BE1AF"
)
boxplot(env.hel$elev,
env.rel$elev,
env.norm$elev,
las = 1,
main = "Standardizations by Sites",
names = c("Hellinger","total","norm"),
col = "#46AFAA"
)
boxplot(env.chi$elev,
env.wis$elev,
las = 1,
main = "Double Standardizations",
names = c("Chi-square","Wisconsin"),
col = "#FAD223"
)
env_cont <- env[,c("elev","temp","hum","soil_moist_avg","jul_date")]
env.log <- data.trans(env_cont, method="log", plot=F)
env.power <- data.trans(env_cont, method="power", exp=0.5, plot=F)
env.asin <- data.trans(env_cont, method="asin", plot=F)
env.scal <- decostand(env_cont, "max") #Standardization by max value of each column
env.relsp <- decostand(env_cont, "total", MARGIN=2) #Standardization by column totals
env.zscore <- decostand(env_cont, "standardize") #Z-scores the data in each column
env.rel <- decostand(env_cont, "total") #Standardization by max value of each site/row
env.norm <- decostand(env_cont, "normalize") #Give a length of 1 to each row vector (chord
#transformation), very useful for Euclidean distances (PCA, RDA) and can be used on
#log-transformed data
env.hel <- decostand(env_cont, "hellinger") #Square root of relative values per site, obtained
#by applying chord transformation to square root transformed data
env.chi <- decostand(env_cont, "chi.square") #Double standardization by columns and rows
env.wis <- wisconsin(env_cont) #Wisconsin standardization, values are ranged by column maxima
#and then by site totals
#Let's see what each of these transformations looks like for the "Max Depth (m)" variable:
par(mfrow = c(2,2))
boxplot(env_cont$elev,
env.power$elev,
env.log$elev,
las = 1,
main = "Simple Transformations",
names = c("raw data","sqrt","log"),
col = "#FF5050"
)
boxplot(env.scal$elev,
env.relsp$elev,
env.zscore$elev,
las = 1,
main = "Standardizations by Variable",
names = c("max","total","Z-score"),
col = "#9BE1AF"
)
boxplot(env.hel$elev,
env.rel$elev,
env.norm$elev,
las = 1,
main = "Standardizations by Sites",
names = c("Hellinger","total","norm"),
col = "#46AFAA"
)
boxplot(env.chi$elev,
env.wis$elev,
las = 1,
main = "Double Standardizations",
names = c("Chi-square","Wisconsin"),
col = "#FAD223"
)
env_cont <- env[,c("elev","temp","hum","soil_moist_avg","jul_date")]
env.log <- data.trans(env_cont, method="log", plot=F)
env.power <- data.trans(env_cont, method="power", exp=0.5, plot=F)
env.asin <- data.trans(env_cont, method="asin", plot=F)
env.scal <- decostand(env_cont, "max") #Standardization by max value of each column
env.relsp <- decostand(env_cont, "total", MARGIN=2) #Standardization by column totals
env.zscore <- decostand(env_cont, "standardize") #Z-scores the data in each column
env.rel <- decostand(env_cont, "total") #Standardization by max value of each site/row
env.norm <- decostand(env_cont, "normalize") #Give a length of 1 to each row vector (chord
#transformation), very useful for Euclidean distances (PCA, RDA) and can be used on
#log-transformed data
env.hel <- decostand(env_cont, "hellinger") #Square root of relative values per site, obtained
#by applying chord transformation to square root transformed data
env.chi <- decostand(env_cont, "chi.square") #Double standardization by columns and rows
env.wis <- wisconsin(env_cont) #Wisconsin standardization, values are ranged by column maxima
#and then by site totals
#Let's see what each of these transformations looks like for the "Max Depth (m)" variable:
par(mfrow = c(4,1))
boxplot(env_cont$elev,
env.power$elev,
env.log$elev,
las = 1,
main = "Simple Transformations",
names = c("raw data","sqrt","log"),
col = "#FF5050"
)
env_cont <- env[,c("elev","temp","hum","soil_moist_avg","jul_date")]
head(env_cont)
pairs(env_cont,
panel = panel.smooth,
main = "Bivariate Plots with Smooth Curves")
P.corr <- cor(env_cont, method = "pearson", use = "complete.obs")
round(P.corr, 2)
dev.off()
corrplot(P.corr,
type = "upper",
order = "hclust",
tl.col = "black",
tl.srt = 45)
p1 <- ggplot(env) + geom_boxplot(aes(x = trt, y = soil_moist_avg), fill = "#FF5050", alpha=0.8)
p2 <- ggplot(env) + geom_boxplot(aes(x = trt, y = temp), fill = "#FF5050", alpha=0.8)
p3 <- ggplot(env) + geom_boxplot(aes(x = trt, y = hum), fill = "#FF5050", alpha=0.8)
p4 <- ggplot(env) + geom_boxplot(aes(x = trt, y = canopy_cov), fill = "#FF5050", alpha=0.8)
p5 <- ggplot(env) + geom_boxplot(aes(x = trt, y = dwd_cov), fill = "#FF5050", alpha=0.8)
ggarrange(p1, p2, p3, p4, p5, ncol=2, nrow=3)
tinytex::tlmgr_update()
tinytex::tlmgr_update()
install.packages('tinytex')
install.packages('tinytex')
tinytex::install_tinytex()
update.packages(ask = FALSE)  # This updates all packages without asking
library(vegan)
library(dplyr)
library(ggplot2)
library(cluster)
library(indicspecies)
#source("C:\\USGS_OCRU\\Teaching\\FW599_Multivariate_Statistics\\Data\\Biostats.R")
setwd("C:/Users/jasmi/OneDrive/Documents/Academic/OSU/Git/multivariate-analysis")
source("Biostats.R")
source("coldiss.R")
dat <- read.csv("Harney_Fishes_2007.csv", row.names = 1)
sub_dat <- subset(dat, SMU=="Malheur")
#We will once again subset the data to include only the Malheur sites since the entire dataset is too large
#to effectively visualize.
spp_N <- colSums(sub_dat[,16:ncol(sub_dat)])
spp_0 <- subset(spp_N, spp_N == 0)
omit <- names(spp_0)
dat2 <- sub_dat[,!(colnames(sub_dat) %in% omit)]
dat3 <- dat2[rowSums(dat2[,16:ncol(dat2)]) >0, ]
dat3$Herbaceous[is.na(dat3$Herbaceous)] <- 0
dat3$Ann_Herb[is.na(dat3$Ann_Herb)] <- 0
dat3 <- dat3[complete.cases(dat3$SiteLength),]
dat_final <- dat3
fish <- dat_final[,16:ncol(dat_final)]
env <- dat_final[,1:15]
fish_red <- drop.var(fish, min.fo=1)
fish_dens <- fish_red
for(i in 1:nrow(fish_red)){
fish_dens[i,] <- fish_red[i,]/env$SiteLength[i]
}
drop <- c("Latitude","Longitude","SiteLength","SiteWidth","SurfaceArea")
env <- env[,!(colnames(env) %in% drop)]
env_cont <- env[,!(colnames(env) %in% c("SMU","Pop","NLCD_Cat"))]
env <- env[,!(colnames(env) %in% c("Ave_Max_D","Ann_Herb"))]
env_cont <- env_cont[,!(colnames(env_cont) %in% c("Ave_Max_D","Ann_Herb"))]
log_fish_abu <- log(fish_red + 1)
log_fish_dens <- log(fish_dens + 1)
env_std <- decostand(env_cont, "max")
fish.bray <- vegdist(log_fish_dens, "bray")
diana_fish <- diana(as.dist(fish.bray))
hclus.cophenetic(fish.bray, diana_fish)
library(vegan)
library(viridis)
setwd("C:/Users/jasmi/OneDrive/Documents/Academic/OSU/Git/multivariate-analysis")
source("Biostats.R")
source("coldiss.R")
dat <- read.csv("Harney_Fishes_2007.csv", row.names = 1)
sub_dat <- subset(dat, SMU=="Malheur")
spp_N <- colSums(sub_dat[,16:ncol(sub_dat)])
spp_0 <- subset(spp_N, spp_N == 0)
omit <- names(spp_0)
dat2 <- sub_dat[,!(colnames(sub_dat) %in% omit)]
dat3 <- dat2[rowSums(dat2[,16:ncol(dat2)]) >0, ]
dat3$Herbaceous[is.na(dat3$Herbaceous)] <- 0
dat3$Ann_Herb[is.na(dat3$Ann_Herb)] <- 0
dat3 <- dat3[complete.cases(dat3$SiteLength),]
dat_final <- dat3
fish <- dat_final[,16:ncol(dat_final)]
fish_red <- drop.var(fish, min.fo=1)
fish_dens <- fish_red
for(i in 1:nrow(fish_red)){
fish_dens[i,] <- fish_red[i,]/dat_final$SiteLength[i]
}
fish_dens_log <- log(fish_dens + 1)
fish.ca <- cca(fish_dens_log)
summary(fish.ca)
100*eigenvals(fish.ca)/sum(eigenvals(fish.ca))
screeplot(fish.ca, bstick=TRUE, main="Inertia, CA vs. Random")
par(mfrow=c(1,2))
plot(fish.ca,
scaling=1,
main="CA of Log-Fish Density, Scaling 1")
plot(fish.ca,
main="CA of Log-Fish Density, Scaling 2")
groups <- levels(factor(dat_final$Pop))
pt_col <- viridis(length(groups))
site.sc <- scores(fish.ca, choices=c(1,2))
p <- ordiplot(fish.ca,
type="n",
main="CA of Log-Fish Density",
xlab="Axis 1",
ylab="Axis 2",
xlim=c(-8,2))
for (i in 1:length(groups))
{
dim_choice <- site.sc$sites[dat_final$Pop==groups[i],]
points(dim_choice[,1], dim_choice[,2],
pch=19,
cex=1.4,
col=pt_col[i])
}
text(site.sc$species*1.2, row.names(site.sc$species))
arrows(0, 0, site.sc$species[,1]*1.1, site.sc$species[,2]*1.1,
lwd=2,
length=0.1)
legend(x="bottomleft",
legend=levels(factor(dat_final$Pop)),
col=pt_col[1:6],
pch=19,
cex=1.2)
dev.off())
dev.off()
p <- ordiplot(fish.ca,
type="n",
main="CA of Log-Fish Density",
xlab="Axis 1",
ylab="Axis 2",
xlim=c(-8,2))
for (i in 1:length(groups))
{
dim_choice <- site.sc$sites[dat_final$Pop==groups[i],]
points(dim_choice[,1], dim_choice[,2],
pch=19,
cex=1.4,
col=pt_col[i])
}
text(site.sc$species*1.2, row.names(site.sc$species))
arrows(0, 0, site.sc$species[,1]*1.1, site.sc$species[,2]*1.1,
lwd=2,
length=0.1)
legend(x="bottomleft",
legend=levels(factor(dat_final$Pop)),
col=pt_col[1:6],
pch=19,
cex=1.2)
fish.bray <- vegdist(fish_dens_log, "bray")
fish.pcoa <- cmdscale(fish.bray,
k=5,
eig=TRUE,
add=T)
fish.pcoa
100*fish.pcoa$eig/sum(fish.pcoa$eig)
plot(100*fish.pcoa$eig/sum(fish.pcoa$eig),
type="b",
lwd=2,
col="blue",
xlab="Principal Component from PCoA",
ylab="Percent variation explained",
main="Broken Stick Model")
lines(bstick(length(fish.pcoa$eig))*100,
type="b",
lwd=2,
col="red")
spe.sc <- wascores(fish.pcoa$points[,1:2], fish_dens_log)
vec.sp <- envfit(as.data.frame(fish.pcoa$points), fish_dens_log, perm=1000)
ordiplot(scores(fish.pcoa, choices=c(1,2)),
type="t",
main="PCoA of Log-Fish Density")
abline(h=0, lty=3)
abline(v=0, lty=3)
points(scores(fish.pcoa, choices=c(1,2)),
pch=19)
plot(vec.sp,
p.max=0.1,
col="blue")
groups <- levels(factor(dat_final$Pop))
pt_col <- viridis(length(groups))
site.sc <- scores(fish.pcoa, choices=c(1,2))
p <- ordiplot(fish.pcoa,
type="n",
main="PCoA of Log-Fish Density",
xlab="Axis 1",
ylab="Axis 2",
xlim=c(-0.8,1))
for (i in 1:length(groups))
{
dim_choice <- site.sc[dat_final$Pop==groups[i],]
points(dim_choice[,1], dim_choice[,2],
pch=19,
cex=1.4,
col=pt_col[i])
}
text(spe.sc*1.5, row.names(spe.sc))
arrows(0, 0, spe.sc[,1]*1.4, spe.sc[,2]*1.4,
lwd=2,
length=0.1)
legend(x="bottomleft",
legend=levels(factor(dat_final$Pop)),
col=pt_col[1:6],
pch=19,
cex=1.2)
fish.nmds2 <- metaMDS(fish_dens_log,
distance="bray",
k=2,
autotransform=FALSE,
trymax=100)
fish.nmds2
fish.nmds3 <- metaMDS(fish_dens_log,
distance="bray",
k=3,
autotransform=FALSE,
trymax=100)
fish.nmds3
nmds.scree(fish_dens_log,
distance="bray",
k=10,
autotransform=FALSE,
trymax=50)
stressplot(fish.nmds2, main="Shepard Plot")
stressplot(fish.nmds3, main="Shepard Plot")
spe.sc <- wascores(fish.nmds2$points[,1:2], fish_dens_log)
vec.sp <- envfit(fish.nmds2$points, fish_dens_log, perm=1000)
spe.sc <- wascores(as.data.frame(fish.nmds2$points[,1:2]), fish_dens_log)
vec.sp <- envfit(as.data.frams(fish.nmds2$points), fish_dens_log, perm=1000)
vec.sp <- envfit(as.data.frame(fish.nmds2$points), fish_dens_log, perm=1000)
plot(fish.nmds2,
choices=c(1,2),
type = "text",
display = "sites",
main="NMDS of Log-Fish Density")
plot(vec.sp,
p.max=0.1,
col="blue")
gof <- goodness(fish.nmds2)
plot(fish.nmds2,
choices=c(1,2),
type = "text",
display = "sites",
main="NMDS of Log-Fish Density")
points(fish.nmds2,
display="sites",
cex=gof*200)
plot(fish.nmds2,
choices=c(1,2),
type = "text",
display = "sites",
main="NMDS of Log-Fish Density")
points(fish.nmds2,
cex=10*fish_dens_log$TROUT_RB)
groups <- levels(factor(dat_final$Pop))
pt_col <- viridis(length(groups))
site.sc <- scores(fish.nmds2, choices=c(1,2))
p <- ordiplot(fish.nmds2,
type="n",
main="NMDS of Log-Fish Density",
xlab="Axis 1",
ylab="Axis 2")
for (i in 1:length(groups))
{
dim_choice <- site.sc$sites[dat_final$Pop==groups[i],]
points(dim_choice[,1], dim_choice[,2],
pch=19,
cex=1.4,
col=pt_col[i])
}
text(site.sc$species, row.names(site.sc$species))
arrows(0, 0, site.sc$species[,1]*0.9, site.sc$species[,2]*0.9,
lwd=2,
length=0.1)
legend(x="topright",
legend=levels(factor(dat_final$Pop)),
col=pt_col[1:6],
pch=19,
cex=1.2)
