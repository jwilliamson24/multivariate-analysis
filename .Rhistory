length(site_level_df$site_id)
length(unique(site_level_df$site_id))
# Find rows with non-unique site_id values (both duplicates and original rows)
non_unique_site_id_df <- site_level_df %>%
filter(site_id %in% site_id[duplicated(site_id)])
# removing duplicate site rows:
# some sites had equal amounts of two different weather types, so the mode function left two rows for that site.
# in these cases, I have chosen to delete one of the rows
site_level_df <- site_level_df[-113,] #deleted C, kept PC.
site_level_df <- site_level_df[-32,] #deleted C, kept PC. partly cloudy feels representative of the mix of C and PC.
site_level_df <- site_level_df[-13,] #deleted PC, kept SN. felt important to know it was snowing
# View the summarized site-level dataframe
str(site_level_df)
site_level_df <- as.data.frame(site_level_df)
df1 <- site_level_df
df2 <- site_dwd
drop <- c(2:6) #drop cols in dwd that are already in site_level
df2 <- df2[, -drop]
df_merged <- df1 %>%
left_join(df2, by = "site_id")
### reorder
new_order <- c("site_id","landowner","tree_farm", "stand","trt",
"year","jul_date","lat","long","weather","elev","temp","hum",
"canopy_cov","veg_cov","dwd_cov","fwd_cov","soil_moist","dwd_count",
"stumps","logs","size_cl","decay_cl","char_cl","length_cl","oss","enes")
dat <- dat[,new_order]
View(dat)
df_merged <- df_merged[,new_order]
write.csv(df_merged, "C:/Users/jasmi/OneDrive/Documents/Academic/OSU/Git/oss-occu/data/site_level_matrix.csv",
row.names = FALSE)
saveRDS(df_merged, "C:/Users/jasmi/OneDrive/Documents/Academic/OSU/Git/oss-occu/data/site_level_matrix.rds")
View(df_merged)
#### Load data -----------------------------------------------------------------
#     site <- read.csv("site.complete.csv")
#     dwd <- read.csv("dwd.complete.csv")
#     subplot <- read.csv("subplot.complete.csv")
#     sals <- read.csv("sals.complete.csv",
#                  colClasses = c(landowner="factor", stand="character", trt="factor",
#                                 obs="factor", subplot="factor", recap="factor",
#                                 pass="factor", spp="factor", cover_obj="factor",
#                                 substrate="factor", age_class="factor"))
dat <- readRDS("site_level_matrix.RDS")
View(dat)
dwd <- dat[,c(19:25)]
View(dwd)
View(dat)
row.names(dat) <- dat[,1]
dwd <- dat[,c(19:25)]
dat <- readRDS("C:/Users/jasmi/OneDrive/Documents/Academic/OSU/Git/oss-occu/data/site_level_matrix.rds")
row.names(dat) <- dat[,1]
sals <- dat[,c("oss","enes","oss_dens","enes_dens","sal_dens")]
sals <- dat[,c("oss","enes")]
drop <- c("lat","long","landowner","stand","tree_farm","year","weather","size_cl",
"length_cl","site_id","oss","enes")
env <- dat[,!(colnames(dat) %in% drop)]
#env_cont <- env[,c("elev","temp","hum","soil_moist","canopy_cov","veg_cov",
#                   "dwd_cov","fwd_cov","jul_date","dwd_dens","decay_cl","char_cl")]
env_cont <- env[, !colnames(env) %in% "trt"]
p1 <- ggplot(env) + geom_boxplot(aes(x = trt, y = soil_moist), fill = "#FF5050", alpha=0.8)
p2 <- ggplot(env) + geom_boxplot(aes(x = trt, y = temp), fill = "#FF5050", alpha=0.8)
p3 <- ggplot(env) + geom_boxplot(aes(x = trt, y = hum), fill = "#FF5050", alpha=0.8)
#p4 <- ggplot(env) + geom_boxplot(aes(x = trt, y = dwd_dens), fill = "#FF5050", alpha=0.8)
#p5 <- ggplot(env) + geom_boxplot(aes(x = trt, y = log_dens), fill = "#FF5050", alpha=0.8)
#p6 <- ggplot(env) + geom_boxplot(aes(x = trt, y = stump_dens), fill = "#FF5050", alpha=0.8)
p7 <- ggplot(env) + geom_boxplot(aes(x = trt, y = decay_cl), fill = "#FF5050", alpha=0.8)
p8 <- ggplot(env) + geom_boxplot(aes(x = trt, y = char_cl), fill = "#FF5050", alpha=0.8)
p9 <- ggplot(env) + geom_boxplot(aes(x = trt, y = dwd_cov), fill = "#FF5050", alpha=0.8)
ggarrange(p1, p2, p3,p7, p8, p9, ncol=2, nrow=3)
View(dwd)
#### Load data -----------------------------------------------------------------
#     site <- read.csv("site.complete.csv")
dwd_all <- read.csv("dwd.complete.csv")
View(dwd_all)
dat <- readRDS("site_level_matrix.RDS")
row.names(dat) <- dat[,1]
dwd <- dat[,c(19:25)]
dwd$dwd_dens <- round(dwd$dwd_count/567,2)
dwd$log_dens <- round(dwd$logs/567,2)
dwd$stump_dens <- round(dwd$stump/567,2)
View(dwd)
dwd <- dat[,c(5,19:25)]
View(dwd)
colnames(dwd)
dwd$dwd_dens <- round(dwd$dwd_count/567,2)
dwd$log_dens <- round(dwd$logs/567,2)
dwd$stump_dens <- round(dwd$stump/567,2)
p1 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = dwd_count), fill = "#FF5050", alpha=0.8)
p2 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = stumps), fill = "#FF5050", alpha=0.8)
p3 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = logs), fill = "#FF5050", alpha=0.8)
p4 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = size_cl), fill = "#FF5050", alpha=0.8)
p5 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = decay_cl), fill = "#FF5050", alpha=0.8)
p6 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = char_cl), fill = "#FF5050", alpha=0.8)
p7 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = length_cl), fill = "#FF5050", alpha=0.8)
p8 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = dwd_dens), fill = "#FF5050", alpha=0.8)
p9 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = log_dens), fill = "#FF5050", alpha=0.8)
ggarrange(p1,p2,p3,p4,p5,p6,p7,p8,p9 ncol=2, nrow=3)
p1 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = dwd_count), fill = "#FF5050", alpha=0.8)
p2 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = stumps), fill = "#FF5050", alpha=0.8)
p3 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = logs), fill = "#FF5050", alpha=0.8)
p4 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = size_cl), fill = "#FF5050", alpha=0.8)
p5 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = decay_cl), fill = "#FF5050", alpha=0.8)
p6 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = char_cl), fill = "#FF5050", alpha=0.8)
p7 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = length_cl), fill = "#FF5050", alpha=0.8)
p8 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = dwd_dens), fill = "#FF5050", alpha=0.8)
p9 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = log_dens), fill = "#FF5050", alpha=0.8)
ggarrange(p1,p2,p3,p4,p5,p6,p7,p8,p9, ncol=3, nrow=3)
p1 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = dwd_count), fill = "#FF5050", alpha=0.8)
p2 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = stumps), fill = "#FF5050", alpha=0.8)
p3 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = logs), fill = "#FF5050", alpha=0.8)
p4 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = size_cl), fill = "#FF5050", alpha=0.8)
p5 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = decay_cl), fill = "#FF5050", alpha=0.8)
p6 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = char_cl), fill = "#FF5050", alpha=0.8)
p7 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = length_cl), fill = "#FF5050", alpha=0.8)
p8 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = dwd_dens), fill = "#FF5050", alpha=0.8)
p9 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = log_dens), fill = "#FF5050", alpha=0.8)
p10 <- ggplot(dwd) + geom_boxplot(aes(x = trt, y = stump_dens), fill = "#FF5050", alpha=0.8)
ggarrange(p1,p2,p3,p4,p5,p6,p7,p8,p9,p10, ncol=3, nrow=4)
library(vegan)
library(nomclust)
library(BioStatR)
library(RColorBrewer)
library(gclus)
setwd("C:/Users/jasmi/OneDrive/Documents/Academic/OSU/Git/multivariate-analysis")
source("Biostats.R")
source("coldiss.R")
#2) Loading site level data
dat2 <- readRDS("C:/Users/jasmi/OneDrive/Documents/Academic/OSU/Git/oss-occu/data/site_level_matrix.rds")
row.names(dat2) <- dat2[,1]
sals <- dat2[,c("oss","enes")]
drop <- c("lat","long","landowner","stand","tree_farm","year","weather","size_cl",
"length_cl","site_id","oss","enes")
env <- dat2[,!(colnames(dat2) %in% drop)]
#env_cont <- env[,c("elev","temp","hum","soil_moist","canopy_cov","veg_cov",
#                   "dwd_cov","fwd_cov","jul_date","dwd_dens","decay_cl","char_cl")]
env_cont <- env[, !colnames(env) %in% "trt"]
View(env_cont)
View(env)
log_sals <- log(sals + 1)
env.zscore <- decostand(env_cont, "standardize") #Z-scores the data in each column
sal_occ <- data.trans(sals, method="power", exp=0, plot=F)
sal.sim <- sm(sal_occ)
sal.jac <- vegdist(sal_occ, method="jaccard")
plot(sal.jac, sal.sim,
xlab="Jaccard's coefficient",
ylab="Simple Matching coefficient",
pch=21,
col="black")
abline(0, 1, col="darkgray")
fish.sor <- vegdist(fish_occ, method="bray")
dat <- read.csv("Harney_Fishes_2007.csv", row.names = 1)
sub_dat <- subset(dat, SMU=="Malheur")
#In this case, we will subset the data to include only the Malheur sites since the entire dataset is too
#large to effectively visualize.
#3) Omitting species with zero observations and sites without fish
spp_N <- colSums(sub_dat[,16:ncol(sub_dat)])
spp_0 <- subset(spp_N, spp_N == 0)
omit <- names(spp_0)
dat2 <- sub_dat[,!(colnames(sub_dat) %in% omit)]
dat3 <- dat2[rowSums(dat2[,16:ncol(dat2)]) >0, ]
#4) Dealing with missing data
dat3$Herbaceous[is.na(dat3$Herbaceous)] <- 0
dat3$Ann_Herb[is.na(dat3$Ann_Herb)] <- 0
dat3 <- dat3[complete.cases(dat3$SiteLength),]
dat_final <- dat3
#5) Splitting the data set into environmental variables and species abundances
fish <- dat_final[,16:ncol(dat_final)]
env <- dat_final[,1:15]
#6) Dropping rare species
fish_red <- drop.var(fish, min.fo=1)
#7) Standardizing species observed abundance by sampling effort
fish_dens <- fish_red
for(i in 1:nrow(fish_red)){
fish_dens[i,] <- fish_red[i,]/env$SiteLength[i]
}
#8) Selecting relevant environmental data without covarying factors
drop <- c("Latitude","Longitude","SiteLength","SiteWidth","SurfaceArea")
env <- env[,!(colnames(env) %in% drop)]
env_cont <- env[,!(colnames(env) %in% c("SMU","Pop","NLCD_Cat"))]
env <- env[,!(colnames(env) %in% c("Ave_Max_D","Ann_Herb"))]
env_cont <- env_cont[,!(colnames(env_cont) %in% c("Ave_Max_D","Ann_Herb"))]
#9) Checking for outliers (remember, we are ignoring them for now)
#10) Transforming and standardizing the data as needed
log_fish_abu <- log(fish_red + 1)
log_fish_dens <- log(fish_dens + 1)
env_std <- decostand(env_cont, "max")
fish_occ <- data.trans(fish_red, method="power", exp=0, plot=F)
#The simple matching coefficient is a symmetric measure of similarity that is computed as the number of
#double 0s and double 1s among a pair of sites divided by the total number of descriptors. Because it
#is a symmetric measure (i.e., double 0s are counted as perfectly similar), it is inappropriate for
#species data.
fish.sim <- sm(fish_occ)
#In contrast, Jaccard's similarity is an asymmetric measure of similarity that is computed as the number
#of double 1's divided by the number of descriptors excluding double 0s. It is generally robust for
#use with species presence/absence data. Note that `vegan` calculates these coefficients as a
#dissimilarity coefficients.
fish.jac <- vegdist(fish_occ, method="jaccard")
#By including double 0s, the simple matching coefficient tends to underestimate the degree of dissimilarity
#between two sites when compared to Jaccard's coefficient.
plot(fish.jac, fish.sim,
xlab="Jaccard's coefficient",
ylab="Simple Matching coefficient",
pch=21,
col="black")
abline(0, 1, col="darkgray")
View(sal_occ)
View(fish_occ)
fish.sor <- vegdist(fish_occ, method="bray")
plot(fish.jac, fish.sor,
xlab="Jaccard's coefficient",
ylab="Sorensen's coefficient",
pch=21,
col="black")
abline(0, 1, col="darkgray")
plot(sal.jac, sal.sim,
xlab="Jaccard's coefficient",
ylab="Simple Matching coefficient",
pch=21,
col="black")
abline(0, 1, col="darkgray")
fish.sor <- vegdist(fish_occ, method="bray")
plot(fish.jac, fish.sor,
xlab="Jaccard's coefficient",
ylab="Sorensen's coefficient",
pch=21,
col="black")
abline(0, 1, col="darkgray")
sal.sor <- vegdist(sal_occ, method="bray")
plot(sal.jac, sal.sor,
xlab="Jaccard's coefficient",
ylab="Sorensen's coefficient",
pch=21,
col="black")
abline(0, 1, col="darkgray")
coldiss(sal.jac, nc=5, byrank=FALSE, diag=TRUE)
sal.bray <- vegdist(log_fish_dens, method="bray")
fish.bray <- vegdist(log_fish_dens, method="bray")
fish.cho <- decostand(fish_dens, "normalize")
fish.cho <- dist(fish.cho)
fish.hel <- decostand(fish_dens, "hellinger")
fish.hel <- dist(fish.hel)
plot(fish.cho, fish.hel,
xlab="Chord distance",
ylab="Hellinger distance",
pch=21,
col="black")
abline(0, 1, col="darkgray")
plot(fish.bray, fish.hel,
xlab="Bray-Curtis distance",
ylab="Hellinger distance",
pch=21,
col="black")
abline(0, 1, col="darkgray")
coldiss(fish.bray, nc=5, byrank=FALSE, diag=TRUE)
coldiss(fish.hel, nc=5, byrank=FALSE, diag=TRUE)
sal.bray <- vegdist(log_fish_dens, method="bray")
#The chord distance is a Euclidean distance computed on site (object) vectors that have been normalized to
#length 1 (also referred to as the chord transformation). The log-chord distance is simply the chord
#distance applied to log-transformed abundance data.
sal.cho <- decostand(sal_dens, "normalize")
sal.bray <- vegdist(log_sals, method="bray")
sal.cho <- decostand(sals, "normalize")
sal.cho <- dist(sal.cho)
sal.hel <- decostand(sal_dens, "hellinger")
sal.hel <- decostand(sals, "hellinger")
sal.hel <- dist(sal.hel)
plot(sal.cho, sal.hel,
xlab="Chord distance",
ylab="Hellinger distance",
pch=21,
col="black")
abline(0, 1, col="darkgray")
plot(sal.bray, sal.hel,
xlab="Bray-Curtis distance",
ylab="Hellinger distance",
pch=21,
col="black")
abline(0, 1, col="darkgray")
coldiss(sal.bray, nc=5, byrank=FALSE, diag=TRUE)
sal.chi <- vegdist(log_fish_abu, method="chi")
sal.chi <- vegdist(log_sals, method="chi")
env <- dat2[,!(colnames(dat2) %in% drop)]
#env_cont <- env[,c("elev","temp","hum","soil_moist","canopy_cov","veg_cov",
#                   "dwd_cov","fwd_cov","jul_date","dwd_dens","decay_cl","char_cl")]
env_cont <- env[, !colnames(env) %in% "trt"]
#10) Transforming and standardizing the data as needed
log_sals <- log(sals + 1)
env.zscore <- decostand(env_cont, "standardize") #Z-scores the data in each c
drop <- c("lat","long","landowner","stand","tree_farm","year","weather","size_cl",
"length_cl","site_id","oss","enes")
env <- dat2[,!(colnames(dat2) %in% drop)]
#env_cont <- env[,c("elev","temp","hum","soil_moist","canopy_cov","veg_cov",
#                   "dwd_cov","fwd_cov","jul_date","dwd_dens","decay_cl","char_cl")]
env_cont <- env[, !colnames(env) %in% "trt"]
#10) Transforming and standardizing the data as needed
log_sals <- log(sals + 1)
env.zscore <- decostand(env_cont, "standardize") #Z-scores th
dat2 <- readRDS("C:/Users/jasmi/OneDrive/Documents/Academic/OSU/Git/oss-occu/data/site_level_matrix.rds")
row.names(dat2) <- dat2[,1]
sals <- dat2[,c("oss","enes")]
drop <- c("lat","long","landowner","stand","tree_farm","year","weather","size_cl",
"length_cl","site_id","oss","enes")
env <- dat2[,!(colnames(dat2) %in% drop)]
#env_cont <- env[,c("elev","temp","hum","soil_moist","canopy_cov","veg_cov",
#                   "dwd_cov","fwd_cov","jul_date","dwd_dens","decay_cl","char_cl")]
env_cont <- env[, !colnames(env) %in% "trt"]
#10) Transforming and standardizing the data as needed
log_sals <- log(sals + 1)
env.zscore <- decostand(env_cont, "standardize") #Z-scores the data in each column
env.std <- decostand(env_cont, "standardize") #Z-scores the data in each column
env.euc <- vegdist(env_std, metric="euclidean")
env.gower <- daisy(env_cont, metric="gower")
plot(env.gower, env.euc,
xlab="Gower dissimilarity",
ylab="Euclidean distance of standardized data",
pch=21,
col="black")
abline(0, 1, col="darkgray")
env.gower <- daisy(env_cont, metric="gower")
plot(env.gower, env.euc,
xlab="Gower dissimilarity",
ylab="Euclidean distance of standardized data",
pch=21,
col="black")
dat2 <- readRDS("C:/Users/jasmi/OneDrive/Documents/Academic/OSU/Git/oss-occu/data/site_level_matrix.rds")
row.names(dat2) <- dat2[,1]
sals <- dat2[,c("oss","enes")]
drop <- c("lat","long","landowner","stand","tree_farm","year","weather","size_cl",
"length_cl","site_id","oss","enes")
env <- dat2[,!(colnames(dat2) %in% drop)]
#env_cont <- env[,c("elev","temp","hum","soil_moist","canopy_cov","veg_cov",
#                   "dwd_cov","fwd_cov","jul_date","dwd_dens","decay_cl","char_cl")]
env_cont <- env[, !colnames(env) %in% "trt"]
#10) Transforming and standardizing the data as needed
log_sals <- log(sals + 1)
env.std <- decostand(env_cont, "standardize") #Z-scores the data in each column
env.euc <- vegdist(env_std, metric="euclidean")
#Gower's coefficient is useful when the dataset contains categorical (or nominal) data. Gower's similarity has
#been designed to handle data of varying mathematical types such that each variable is treated separately.
#This is also a symmetrical coefficient with a structure similar to that of the simple matching coefficient
#when variables are binary or categorical.
env.gower <- daisy(env_cont, metric="gower")
plot(env.gower, env.euc,
xlab="Gower dissimilarity",
ylab="Euclidean distance of standardized data",
pch=21,
col="black")
dat <- read.csv("Harney_Fishes_2007.csv", row.names = 1)
sub_dat <- subset(dat, SMU=="Malheur")
#In this case, we will subset the data to include only the Malheur sites since the entire dataset is too
#large to effectively visualize.
#3) Omitting species with zero observations and sites without fish
spp_N <- colSums(sub_dat[,16:ncol(sub_dat)])
spp_0 <- subset(spp_N, spp_N == 0)
omit <- names(spp_0)
dat2 <- sub_dat[,!(colnames(sub_dat) %in% omit)]
dat3 <- dat2[rowSums(dat2[,16:ncol(dat2)]) >0, ]
#4) Dealing with missing data
dat3$Herbaceous[is.na(dat3$Herbaceous)] <- 0
dat3$Ann_Herb[is.na(dat3$Ann_Herb)] <- 0
dat3 <- dat3[complete.cases(dat3$SiteLength),]
dat_final <- dat3
#5) Splitting the data set into environmental variables and species abundances
fish <- dat_final[,16:ncol(dat_final)]
env <- dat_final[,1:15]
#6) Dropping rare species
fish_red <- drop.var(fish, min.fo=1)
#7) Standardizing species observed abundance by sampling effort
fish_dens <- fish_red
for(i in 1:nrow(fish_red)){
fish_dens[i,] <- fish_red[i,]/env$SiteLength[i]
}
#8) Selecting relevant environmental data without covarying factors
drop <- c("Latitude","Longitude","SiteLength","SiteWidth","SurfaceArea")
env <- env[,!(colnames(env) %in% drop)]
env_cont <- env[,!(colnames(env) %in% c("SMU","Pop","NLCD_Cat"))]
env <- env[,!(colnames(env) %in% c("Ave_Max_D","Ann_Herb"))]
env_cont <- env_cont[,!(colnames(env_cont) %in% c("Ave_Max_D","Ann_Herb"))]
#9) Checking for outliers (remember, we are ignoring them for now)
#10) Transforming and standardizing the data as needed
log_fish_abu <- log(fish_red + 1)
log_fish_dens <- log(fish_dens + 1)
env_std <- decostand(env_cont, "max")
env.euc <- vegdist(env_std, metric="euclidean")
#Gower's coefficient is useful when the dataset contains categorical (or nominal) data. Gower's similarity has
#been designed to handle data of varying mathematical types such that each variable is treated separately.
#This is also a symmetrical coefficient with a structure similar to that of the simple matching coefficient
#when variables are binary or categorical.
env.gower <- daisy(env_cont, metric="gower")
plot(env.gower, env.euc,
xlab="Gower dissimilarity",
ylab="Euclidean distance of standardized data",
pch=21,
col="black")
abline(0, 1, col="darkgray")
dat2 <- readRDS("C:/Users/jasmi/OneDrive/Documents/Academic/OSU/Git/oss-occu/data/site_level_matrix.rds")
row.names(dat2) <- dat2[,1]
sals <- dat2[,c("oss","enes")]
drop <- c("lat","long","landowner","stand","tree_farm","year","weather","size_cl",
"length_cl","site_id","oss","enes")
env <- dat2[,!(colnames(dat2) %in% drop)]
#env_cont <- env[,c("elev","temp","hum","soil_moist","canopy_cov","veg_cov",
#                   "dwd_cov","fwd_cov","jul_date","dwd_dens","decay_cl","char_cl")]
env_cont <- env[, !colnames(env) %in% "trt"]
#10) Transforming and standardizing the data as needed
log_sals <- log(sals + 1)
env_std <- decostand(env_cont, "standardize") #Z-scores the data in each column
env.euc <- vegdist(env_std, metric="euclidean")
#Gower's coefficient is useful when the dataset contains categorical (or nominal) data. Gower's similarity has
#been designed to handle data of varying mathematical types such that each variable is treated separately.
#This is also a symmetrical coefficient with a structure similar to that of the simple matching coefficient
#when variables are binary or categorical.
env.gower <- daisy(env_cont, metric="gower")
plot(env.gower, env.euc,
xlab="Gower dissimilarity",
ylab="Euclidean distance of standardized data",
pch=21,
col="black")
abline(0, 1, col="darkgray")
View(env_std)
View(env_cont)
fish_pa.t <- t(fish_occ)
fish.t.jac <- vegdist(fish_pa.t, "jaccard")
coldiss(fish.t.jac, diag=TRUE)
plot(sal.bray, sal.hel,
xlab="Bray-Curtis distance",
ylab="Hellinger distance",
pch=21,
col="black")
abline(0, 1, col="darkgray")
coldiss(sal.bray, nc=5, byrank=FALSE, diag=TRUE)
coldiss(sal.bray, byrank=FALSE, diag=TRUE)
coldiss(sal.bray, diag=TRUE)
fish_dens.t <- t(log_fish_dens)
fish.pears <- cor(fish_dens)
fish.ken <- cor(fish_dens, method="kendall")
fish.t.chi <- decostand(fish_dens.t, "chi.square")
fish.t.chi2 <- dist(fish.t.chi) #Chi-square
coldiss(fish.pears, diag=TRUE)
coldiss(fish.ken, diag=TRUE)
coldiss(fish.t.chi2, diag=TRUE)
coldiss(fish.pears, diag=TRUE)
coldiss(fish.ken, diag=TRUE)
coldiss(fish.t.chi2, diag=TRUE)
sal_pa.t <- t(sal_occ)
sal.t.jac <- vegdist(sal_pa.t, "jaccard")
coldiss(sal.t.jac, diag=TRUE)
sal_dens.t <- t(log_sals)
sal.pears <- cor(sals)
sal.ken <- cor(sals, method="kendall")
sal.t.chi <- decostand(sals.t, "chi.square")
sals.t <- t(log_sals)
sal.pears <- cor(sals)
sal.ken <- cor(sals, method="kendall")
sal.t.chi <- decostand(sals.t, "chi.square")
sal.t.chi2 <- dist(sal.t.chi) #Chi-square
coldiss(sal.pears, diag=TRUE)
coldiss(sal.ken, diag=TRUE)
coldiss(sal.t.chi2, diag=TRUE)
env.pearson <- cor(env_std)
env.o <- order.single(env.pearson)
pairs(env_std[, env.o],
lower.panel = panel.smooth,
upper.panel = panel.cor,
diag.panel = panel.hist,
main = "Pearson Correlation Matrix")
View(env)
colnames(env_etd)
colnames(env_std)
#Quantitative variables such as environmental data must be dimensionally homogeneous (i.e., standardized)
#prior to R-mode analysis. For variables with largely linear relationships, Pearson's correlation coefficient
#is sufficient.
drop <- c("jul_date","canopy_cov,veg_cov","fwd_cov","stumps","logs","decay_cl","char_cl" )
env_std_subset <- env_std[,!(colnames(env_std) %in% drop)]
env.pearson <- cor(env_std_subset)
env.o <- order.single(env.pearson)
pairs(env_std[, env.o],
lower.panel = panel.smooth,
upper.panel = panel.cor,
diag.panel = panel.hist,
main = "Pearson Correlation Matrix")
warnings()
drop <- c("jul_date","canopy_cov","veg_cov","fwd_cov","stumps","logs","decay_cl","char_cl" )
env_std_subset <- env_std[,!(colnames(env_std) %in% drop)]
env.pearson <- cor(env_std_subset)
env.o <- order.single(env.pearson)
pairs(env_std[, env.o],
lower.panel = panel.smooth,
upper.panel = panel.cor,
diag.panel = panel.hist,
main = "Pearson Correlation Matrix")
View(env_std_subset)
#Quantitative variables such as environmental data must be dimensionally homogeneous (i.e., standardized)
#prior to R-mode analysis. For variables with largely linear relationships, Pearson's correlation coefficient
#is sufficient.
drop <- c("jul_date","canopy_cov","veg_cov","fwd_cov","stumps","logs","decay_cl","char_cl" )
env_std_subset <- env_std[,!(colnames(env_std) %in% drop)]
View(env_std_subset)
env.pearson <- cor(env_std_subset)
env.o <- order.single(env.pearson)
pairs(env_std_subset[, env.o],
lower.panel = panel.smooth,
upper.panel = panel.cor,
diag.panel = panel.hist,
main = "Pearson Correlation Matrix")
env.ken <- cor(env_std_subset, method="kendall")
env.o <- order.single(env.ken)
pairs(env_std_subset[, env.o],
lower.panel = panel.smooth,
upper.panel = panel.cor,
method = "kendall",
diag.panel = panel.hist,
main = "Kendall Correlation Matrix")
