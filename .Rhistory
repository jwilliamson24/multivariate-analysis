drop <- c("lat","long")
env <- env[,!(colnames(env) %in% drop)]
env_cont <- env[,c("elev","temp","hum","soil_moist","canopy_cov","veg_cov","dwd_cov","fwd_cov","jul_date")]
# #Subplot-level data
#     sals <- dat[,24:29]
#     env <- dat[,1:22]
#
#     sals_red <- drop.var(sals, min.fo=5) #Removing very rare species:
#
# 	#Standardizing by unit effort (segment length) to ind/m:
#   # 		fish_dens <- fish_red
#   # 		for(i in 1:nrow(fish_red)){
#   #   		fish_dens[i,] <- fish_red[i,]/env$SiteLength[i]     }
#
# 	#Trimming the environmental data set:
#
#   		drop <- c("date","lat","long")
#   		env <- env[,!(colnames(env) %in% drop)]
#   		head(env)
#   		stat.desc(env)
#
#   		#We can also parse out continuous variables first
#
#   		env_cont <- env[,c("elev","temp","hum","soil_moist_avg","canopy_cov","veg_cov","dwd_cov","fwd_cov")]
#   		head(env_cont)
#Start Exploring Data
#Checking for multivariate outliers:
saloutlier <- mv.outliers(sals, method = "euclidean", sd.limit=2)
envoutlier <- mv.outliers(env_cont, method = "euclidean", sd.limit=2)
intersect(rownames(saloutlier),rownames(envoutlier))
#There is one site that repeats in both outlier dfs. "12213 _ 1 _ 2023"
#Remove co-varying environmental factors:
# env <- env[,!(colnames(env) %in% c("Ave_Max_D"))]
# env_cont <- env_cont[,!(colnames(env_cont) %in% c("Ave_Max_D","Ann_Herb"))]
### Distribution of Data: Fish Abundance
#Let's first re-examine how fish abundances are distributed.
#A barplot of the distribution:
ac <- table(unlist(sals))
dev.off()
barplot(ac,
las = 1,
xlab = "Abundance class",
ylab = "Frequency",
col = gray(length(ac): 0/length(ac)),
ylim=c(0,150)
)
#over 5000 zeros in the oss occu data
#The data are right skewed and also what we would call "zero-skewed."
#We can see that the skewness of the dataset indicates it will need to be transformed!
### Transformation and Standardization
#Examine the distributional properties of the data using the `uv.plots()` function.
#They will definitely need to be transformed.
uv.plots(sals)
# oss and enes are the only spp with enough data
#cloglog???????????????????????????????????????????????????????????
#You can do this item-by-item.
par(mfrow = c(2,2))
hist(sals$oss,
xlab="count",
ylab="Frequency",
main="Raw")
hist(sqrt(sals$oss),
xlab="count",
ylab="Frequency",
main="Square Root")
hist(log(sals$oss),
xlab="count",
ylab="Frequency",
main="Log")
hist(log(sals$oss+0.1),
xlab="count",
ylab="Frequency",
main="Log + 1")
#so many zeros, makes it hard to figure this out. do i have enough data for this?
#We also can use the data.trans() function to play with transformations:
data.trans(sals, method="log", plot=F) #For heavily skewed data
data.trans(sals, method="power", exp=0.5, plot=F) #For slightly skewed data
data.trans(sals, method="asin", plot=F) #For proportional data (scaled 0-1, not relevant here)
#We can use the `decostand()` function in the "vegan" package to standardize the data.
#See `?decostand` for more information.
par(mfrow = c(3,2))
hist(sals$oss,
xlab="count",
ylab="Frequency",
main="Raw")
hist(sqrt(sals$oss),
xlab="count",
ylab="Frequency",
main="Square Root")
hist(log(sals$oss),
xlab="count",
ylab="Frequency",
main="Log")
hist(log(sals$oss+0.1),
xlab="count",
ylab="Frequency",
main="Log + 0.1")
hist(log(sals$oss+1),
xlab="count",
ylab="Frequency",
main="Log + 1")
knitr::opts_chunk$set(echo = TRUE)
setwd("C:/Users/jasmi/OneDrive/Documents/Academic/OSU/Git/multivariate-analysis")
library(vegan)
library(pastecs)
library(corrplot)
library(ggplot2)
library(ggpubr)
source("biostats.R")
#subplot-level
plot <- read.csv("habitat.occu.complete.csv",row.names=1)
allsals <- plot[,23:28]
#site-level
dat <- readRDS("site_level_df.rds")
row.names(dat) <- dat[,1]
sals <- dat[19:20]
env <- dat[1:18]
drop <- c("lat","long")
env <- env[,!(colnames(env) %in% drop)]
env_cont <- env[,c("elev","temp","hum","soil_moist","canopy_cov","veg_cov","dwd_cov","fwd_cov","jul_date")]
par(mfrow = c(3,2))
hist(env$elev,
xlab="elev",
main=NA)
hist(env$temp,
xlab="temp",
main=NA)
hist(env$soil_moist,
xlab="soil moist",
main=NA)
hist(env$hum,
xlab="hum",
main=NA)
hist(env$dwd_cov,
xlab="dwd",
main=NA)
env.log <- data.trans(env_cont, method="log", plot=F)
env.power <- data.trans(env_cont, method="power", exp=0.5, plot=F)
env.asin <- data.trans(env_cont, method="asin", plot=F)
#What about standardization?
stat.desc(env_cont)
#It looks like cv values are still low; however, we know that these variables are mixed-scale!
env.scal <- decostand(env_cont, "max") #Standardization by max value of each column
env.relsp <- decostand(env_cont, "total", MARGIN=2) #Standardization by column totals
env.zscore <- decostand(env_cont, "standardize") #Z-scores the data in each column
env.rel <- decostand(env_cont, "total") #Standardization by max value of each site/row
env.norm <- decostand(env_cont, "normalize") #Give a length of 1 to each row vector (chord
#transformation), very useful for Euclidean distances (PCA, RDA) and can be used on
#log-transformed data
env.hel <- decostand(env_cont, "hellinger") #Square root of relative values per site, obtained
#by applying chord transformation to square root transformed data
env.chi <- decostand(env_cont, "chi.square") #Double standardization by columns and rows
env.wis <- wisconsin(env_cont) #Wisconsin standardization, values are ranged by column maxima
#and then by site totals
par(mfrow = c(2,2))
boxplot(env_cont$temp,
env.power$temp,
env.log$temp,
las = 1,
main = "Simple Transformations",
names = c("raw data","sqrt","log"),
col = "#FF5050"
)
boxplot(env.scal$temp,
env.relsp$temp,
env.zscore$temp,
las = 1,
main = "Standardizations by Variable",
names = c("max","total","Z-score"),
col = "#9BE1AF"
)
boxplot(env.hel$temp,
env.rel$temp,
env.norm$temp,
las = 1,
main = "Standardizations by Sites",
names = c("Hellinger","total","norm"),
col = "#46AFAA"
)
boxplot(env.chi$temp,
env.wis$temp,
las = 1,
main = "Double Standardizations",
names = c("Chi-square","Wisconsin"),
col = "#FAD223"
)
par(mfrow = c(3,2))
hist(env.zscore$elev,
xlab="elev",
main=NA)
hist(env.zscore$temp,
xlab="temp",
main=NA)
hist(env.zscore$soil_moist,
xlab="soil moist",
main=NA)
hist(env.zscore$hum,
xlab="hum",
main=NA)
hist(env.zscore$dwd_cov,
xlab="dwd",
main=NA)
library(vegan)
library(nomclust)
library(BioStatR)
library(RColorBrewer)
library(gclus)
setwd("C:/Users/jasmi/OneDrive/Documents/Academic/OSU/Git/multivariate-analysis")
source("Biostats.R")
source("coldiss.R")
# source("C:\\USGS_OCRU\\Teaching\\FW599_Multivariate_Statistics\\Data\\Biostats.R")
# source("C:\\USGS_OCRU\\Teaching\\FW599_Multivariate_Statistics\\Data\\coldiss.R")
#2) Loading site level data
dat2 <- readRDS("site_level_df.rds")
row.names(dat2) <- dat2[,1]
sals <- dat2[19:20]
env <- dat2[1:18]
drop <- c("lat","long")
env <- env[,!(colnames(env) %in% drop)]
env_cont <- env[,c("elev","temp","hum","soil_moist","canopy_cov","veg_cov","dwd_cov","fwd_cov","jul_date")]
#10) Transforming and standardizing the data as needed
log_sals <- log(sals + 1)
env.zscore <- decostand(env_cont, "standardize") #Z-scores the data in each column
sal_occ <- data.trans(sals, method="power", exp=0, plot=F)
View(sal_occ)
sal.sim <- sm(sal_occ)
sal.jac <- vegdist(sal_occ, method="jaccard")
plot(sal.jac, sal.sim,
xlab="Jaccard's coefficient",
ylab="Simple Matching coefficient",
pch=21,
col="black")
abline(0, 1, col="darkgray")
dev.off()
plot(sal.jac, sal.sim,
xlab="Jaccard's coefficient",
ylab="Simple Matching coefficient",
pch=21,
col="black")
abline(0, 1, col="darkgray")
library(vegan)
library(nomclust)
library(BioStatR)
library(RColorBrewer)
library(gclus)
setwd("C:/Users/jasmi/OneDrive/Documents/Academic/OSU/Git/multivariate-analysis")
source("Biostats.R")
source("coldiss.R")
# source("C:\\USGS_OCRU\\Teaching\\FW599_Multivariate_Statistics\\Data\\Biostats.R")
# source("C:\\USGS_OCRU\\Teaching\\FW599_Multivariate_Statistics\\Data\\coldiss.R")
#2) Loading the data
dat <- read.csv("Harney_Fishes_2007.csv", row.names = 1)
sub_dat <- subset(dat, SMU=="Malheur")
#In this case, we will subset the data to include only the Malheur sites since the entire dataset is too
#large to effectively visualize.
#3) Omitting species with zero observations and sites without fish
spp_N <- colSums(sub_dat[,16:ncol(sub_dat)])
spp_0 <- subset(spp_N, spp_N == 0)
omit <- names(spp_0)
dat2 <- sub_dat[,!(colnames(sub_dat) %in% omit)]
dat3 <- dat2[rowSums(dat2[,16:ncol(dat2)]) >0, ]
#4) Dealing with missing data
dat3$Herbaceous[is.na(dat3$Herbaceous)] <- 0
dat3$Ann_Herb[is.na(dat3$Ann_Herb)] <- 0
dat3 <- dat3[complete.cases(dat3$SiteLength),]
dat_final <- dat3
#5) Splitting the data set into environmental variables and species abundances
fish <- dat_final[,16:ncol(dat_final)]
env <- dat_final[,1:15]
#6) Dropping rare species
fish_red <- drop.var(fish, min.fo=1)
#7) Standardizing species observed abundance by sampling effort
fish_dens <- fish_red
for(i in 1:nrow(fish_red)){
fish_dens[i,] <- fish_red[i,]/env$SiteLength[i]
}
#8) Selecting relevant environmental data without covarying factors
drop <- c("Latitude","Longitude","SiteLength","SiteWidth","SurfaceArea")
env <- env[,!(colnames(env) %in% drop)]
env_cont <- env[,!(colnames(env) %in% c("SMU","Pop","NLCD_Cat"))]
env <- env[,!(colnames(env) %in% c("Ave_Max_D","Ann_Herb"))]
env_cont <- env_cont[,!(colnames(env_cont) %in% c("Ave_Max_D","Ann_Herb"))]
#9) Checking for outliers (remember, we are ignoring them for now)
#10) Transforming and standardizing the data as needed
log_fish_abu <- log(fish_red + 1)
log_fish_dens <- log(fish_dens + 1)
env_std <- decostand(env_cont, "max")
## Q-Mode: (Dis)similarity and Distance Matrices
### (Dis)similarity Coefficients for Species Presence/Absence (Binary) Data
#Analyses can be performed on binary (0-1) data, including for species presence/absence data when binary
#values are the only data available or when abundances are irrelevant.
#Since our class dataset is quantitative, we'll first convert it to a presence/absence format using the
#following transformation:
fish_occ <- data.trans(fish_red, method="power", exp=0, plot=F)
#The simple matching coefficient is a symmetric measure of similarity that is computed as the number of
#double 0s and double 1s among a pair of sites divided by the total number of descriptors. Because it
#is a symmetric measure (i.e., double 0s are counted as perfectly similar), it is inappropriate for
#species data.
fish.sim <- sm(fish_occ)
#In contrast, Jaccard's similarity is an asymmetric measure of similarity that is computed as the number
#of double 1's divided by the number of descriptors excluding double 0s. It is generally robust for
#use with species presence/absence data. Note that `vegan` calculates these coefficients as a
#dissimilarity coefficients.
fish.jac <- vegdist(fish_occ, method="jaccard")
#By including double 0s, the simple matching coefficient tends to underestimate the degree of dissimilarity
#between two sites when compared to Jaccard's coefficient.
plot(fish.jac, fish.sim,
xlab="Jaccard's coefficient",
ylab="Simple Matching coefficient",
pch=21,
col="black")
abline(0, 1, col="darkgray")
library(vegan)
library(dplyr)
library(ggplot2)
library(cluster)
library(indicspecies)
#source("C:\\USGS_OCRU\\Teaching\\FW599_Multivariate_Statistics\\Data\\Biostats.R")
setwd("C:/Users/jasmi/OneDrive/Documents/Academic/OSU/Git/multivariate-analysis")
source("Biostats.R")
source("coldiss.R")
dat <- read.csv("Harney_Fishes_2007.csv", row.names = 1)
sub_dat <- subset(dat, SMU=="Malheur")
spp_N <- colSums(sub_dat[,16:ncol(sub_dat)])
spp_0 <- subset(spp_N, spp_N == 0)
omit <- names(spp_0)
dat2 <- sub_dat[,!(colnames(sub_dat) %in% omit)]
dat3 <- dat2[rowSums(dat2[,16:ncol(dat2)]) >0, ]
dat3$Herbaceous[is.na(dat3$Herbaceous)] <- 0
dat3$Ann_Herb[is.na(dat3$Ann_Herb)] <- 0
dat3 <- dat3[complete.cases(dat3$SiteLength),]
dat_final <- dat3
fish <- dat_final[,16:ncol(dat_final)]
env <- dat_final[,1:15]
fish_red <- drop.var(fish, min.fo=1)
fish_dens <- fish_red
for(i in 1:nrow(fish_red)){
fish_dens[i,] <- fish_red[i,]/env$SiteLength[i]
}
drop <- c("Latitude","Longitude","SiteLength","SiteWidth","SurfaceArea")
env <- env[,!(colnames(env) %in% drop)]
env_cont <- env[,!(colnames(env) %in% c("SMU","Pop","NLCD_Cat"))]
env <- env[,!(colnames(env) %in% c("Ave_Max_D","Ann_Herb"))]
env_cont <- env_cont[,!(colnames(env_cont) %in% c("Ave_Max_D","Ann_Herb"))]
log_fish_abu <- log(fish_red + 1)
log_fish_dens <- log(fish_dens + 1)
env_std <- decostand(env_cont, "max")
fish.bray <- vegdist(log_fish_dens, "bray")
diana_fish <- diana(as.dist(fish.bray))
hclus.cophenetic(fish.bray, diana_fish)
hclus.scree(diana_fish)
plot(diana_fish, which=2, main="DIANA Dendrogram",
xlab="Sites",
ylab="Bray-Curtis Dissimilarity",
hang=-1)
rect.hclust(diana_fish, k=5)
fishcl.class <- cutree(diana_fish, k=5)
fish_dat_new <- cbind(fishcl.class, log_fish_dens)
par(mfrow=c(3,3))
box.plots(fish_dat_new, by="fishcl.class")
nhclus.scree(fish.bray, max.k = 20)
dev.off()
plot(diana_fish, which=2, main="DIANA Dendrogram",
xlab="Sites",
ylab="Bray-Curtis Dissimilarity",
hang=-1)
rect.hclust(diana_fish, k=5)
fishcl.class <- cutree(diana_fish, k=5)
fish_dat_new <- cbind(fishcl.class, log_fish_dens)
par(mfrow=c(3,3))
box.plots(fish_dat_new, by="fishcl.class")
nhclus.scree(fish.bray, max.k = 20)
#The desired number of clusters must be set a-priori by the user. Based on our previous analyses, we can
#guess that somewhere between 4-6 clusters is optimal for this dataset. If we're still unsure, we can
#examine an elbow plot and silhouette width plot te get a better sense for the optimal number of clusters.
dev.off()
nhclus.scree(fish.bray, max.k = 20)
#The desired number of clusters must be set a-priori by the user. Based on our previous analyses, we can
#guess that somewhere between 4-6 clusters is optimal for this dataset. If we're still unsure, we can
#examine an elbow plot and silhouette width plot te get a better sense for the optimal number of clusters.
dev.off()
nhclus.scree(fish.bray, max.k = 20)
fishcl.kmeans.cas <- cascadeKM(fish.bray, inf.gr=2, sup.gr=10, iter=100)
plot(fishcl.kmeans.cas, sortg=T)
fishcl.kmeans.cas$results
fish.kmeans <- kmeans(fish.bray, centers=4, iter.max=10000, nstart=10)
fish.kmeans
plot(log_fish_dens$TROUT_RB, log_fish_dens$DACE_UNID,
col = fish.kmeans$cluster,
pch = 19,
main = "K-Means Clustering with 4 Clusters",
xlab="Redband trout",
ylab="Dace")
env.euc <- vegdist(env_std, metric="euclidean")
envcl.kmeans.cas <- cascadeKM(env.euc, inf.gr=2, sup.gr=10, iter=100)
plot(envcl.kmeans.cas, sortg=T)
envcl.kmeans.cas$results
env.kmeans <- kmeans(env.euc, centers=4, iter.max=10000, nstart=10)
env.kmeans
env.class <- env.kmeans$cluster
env_dat_new<-cbind(env.class, env_std)
par(mfrow=c(2,3))
box.plots(env_dat_new, by="env.class")
site_num <- env$Pop
ind_sp <- multipatt(log_fish_dens, site_num, func = "IndVal.g", control = how(nperm=999))
summary(ind_sp)
fish.kmeans <- kmeans(fish.bray, centers=4, iter.max=10000, nstart=10)
fish.kmeans
plot(log_fish_dens$TROUT_RB, log_fish_dens$DACE_UNID,
col = fish.kmeans$cluster,
pch = 19,
main = "K-Means Clustering with 4 Clusters",
xlab="Redband trout",
ylab="Dace")
dev.off()
plot(log_fish_dens$TROUT_RB, log_fish_dens$DACE_UNID,
col = fish.kmeans$cluster,
pch = 19,
main = "K-Means Clustering with 4 Clusters",
xlab="Redband trout",
ylab="Dace")
env.euc <- vegdist(env_std, metric="euclidean")
envcl.kmeans.cas <- cascadeKM(env.euc, inf.gr=2, sup.gr=10, iter=100)
plot(envcl.kmeans.cas, sortg=T)
envcl.kmeans.cas$results
env.kmeans <- kmeans(env.euc, centers=4, iter.max=10000, nstart=10)
env.kmeans
env.class <- env.kmeans$cluster
env_dat_new<-cbind(env.class, env_std)
par(mfrow=c(2,3))
box.plots(env_dat_new, by="env.class")
site_num <- env$Pop
ind_sp <- multipatt(log_fish_dens, site_num, func = "IndVal.g", control = how(nperm=999))
summary(ind_sp)
site_num <- env$NLCD_Cat
ind_sp <- multipatt(log_fish_dens, site_num, func = "IndVal.g", control = how(nperm=999))
summary(ind_sp)
envcl.ward <- hclust(env.euc, method = "ward.D")
plot(envcl.ward, main="Ward Dendrogram",
xlab="Sites",
ylab="Euclidean Distance",
hang=-1)
dev.off()
plot(envcl.ward, main="Ward Dendrogram",
xlab="Sites",
ylab="Euclidean Distance",
hang=-1)
rect.hclust(envcl.ward, k=4)
ENV_CLUS <- cutree(envcl.ward, k=4)
par(mfrow=c(2,2))
plot(as.factor(ENV_CLUS), env_cont$Max_Depth,
ylim=c(0,1),
col = rgb(red = 0, green = 0, blue = 0, alpha = 0.35),
main = "Max Depth",
ylab = "Max depth (m)",
xlab="Cluster")
points(ENV_CLUS, env_cont$Max_Depth,
pch=19,
cex=1.5,
col = rgb(red = 0, green = 0, blue = 1, alpha = 0.4))
plot(as.factor(ENV_CLUS), env_cont$Gradient,
ylim=c(0,0.06),
col = rgb(red = 0, green = 0, blue = 0, alpha = 0.35),
main = "Gradient",
ylab = "Gradient (%)",
xlab="Cluster")
points(ENV_CLUS, env_cont$Gradient,
pch=19,
cex=1.5,
col = rgb(red = 0, green = 0, blue = 1, alpha = 0.4))
plot(as.factor(ENV_CLUS), env_cont$Elev,
ylim=c(1200,2000),
col = rgb(red = 0, green = 0, blue = 0, alpha = 0.35),
main = "Elevation",
ylab = "Elevation (m)",
xlab="Cluster")
points(ENV_CLUS, env_cont$Elev,
pch=19,
cex=1.5,
col = rgb(red = 0, green = 0, blue = 1, alpha = 0.4))
plot(as.factor(ENV_CLUS), env_cont$Canopy,
ylim=c(0,100),
col = rgb(red = 0, green = 0, blue = 0, alpha = 0.35),
main = "Canopy Cover",
ylab = "Canopy cover (%)",
xlab="Cluster")
points(ENV_CLUS, env_cont$Canopy,
pch=19,
cex=1.5,
col = rgb(red = 0, green = 0, blue = 1, alpha = 0.4))
site_num <- ENV_CLUS
ind_sp <- multipatt(log_fish_dens, site_num, func = "IndVal.g", control = how(nperm=999))
summary(ind_sp)
View(fish_occ)
View(sal_occ)
sal_occ <- data.trans(sals, method="power", exp=0, plot=F)
#The simple matching coefficient is a symmetric measure of similarity that is computed as the number of
#double 0s and double 1s among a pair of sites divided by the total number of descriptors. Because it
#is a symmetric measure (i.e., double 0s are counted as perfectly similar), it is inappropriate for
#species data.
sal.sim <- sm(sal_occ)
#In contrast, Jaccard's similarity is an asymmetric measure of similarity that is computed as the number
#of double 1's divided by the number of descriptors excluding double 0s. It is generally robust for
#use with species presence/absence data. Note that `vegan` calculates these coefficients as a
#dissimilarity coefficients.
sal.jac <- vegdist(sal_occ, method="jaccard")
plot(sal.jac, sal.sim,
xlab="Jaccard's coefficient",
ylab="Simple Matching coefficient",
pch=21,
col="black")
abline(0, 1, col="darkgray")
